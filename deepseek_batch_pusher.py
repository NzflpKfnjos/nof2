import json
import aiohttp
import asyncio
import logging
import time
import re
from concurrent.futures import ThreadPoolExecutor
from config import DEEPSEEK_API_KEY, DEEPSEEK_MODEL, DEEPSEEK_URL, OPEN_WHITELIST, MIN_QUOTE_VOLUME_USDT
from database import redis_client
from volume_stats import (
    calc_volume_compare, get_open_interest, get_funding_rate, get_24hr_change, calc_smart_sentiment,
    get_oi_history, get_top_position_ratio, get_top_account_ratio, get_global_account_ratio)
from account_positions import account_snapshot, tp_sl_cache

KEY_REQ = "deepseek_analysis_request_history"
KEY_RES = "deepseek_analysis_response_history"

# æ‰¹é‡ç¼“å­˜
batch_cache = {}
required_intervals = ["1d", "4h", "1h", "15m", "5m"]

# æ·»åŠ åˆ° batch
def add_to_batch(symbol, interval, klines, indicators):
    if symbol not in batch_cache:
        batch_cache[symbol] = {}
    batch_cache[symbol][interval] = {"klines": klines, "indicators": indicators}

# åˆ¤æ–­æ˜¯å¦å¯ä»¥æ¨é€
def _is_ready_for_push():
    for _, cycles in batch_cache.items():
        for tf in required_intervals:
            if tf not in cycles:
                return False
    return True

# æƒ…ç»ªåˆ†æ•°è½¬æ¢äº¤æ˜“ä¿¡å·
def sentiment_to_signal(score):
    if score >= 85:
        return "ğŸš¨ æç«¯è¿‡çƒ­ | è­¦æƒ•é¡¶éƒ¨åè½¬"
    if score >= 70:
        return "ğŸŸ¢ ç‰›åŠ¿å¼ºåŠ² |"
    if score >= 50:
        return "âšª ä¸­æ€§éœ‡è¡ | è€å¿ƒç­‰å¾…çªç ´"
    if score >= 30:
        return "ğŸŸ¡ ææ…Œç¼“è§£"
    return "ğŸ”¥ æåº¦ææ…Œ"

def _read_prompt():
    """
    è¯»å– prompt.txt å†…å®¹ä½œä¸ºç³»ç»Ÿæç¤ºã€‚
    å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™è¿”å›é»˜è®¤æç¤ºã€‚
    """
    try:
        with open("prompt.txt", "r", encoding="utf-8") as f:
            text = f.read()
            whitelist = ", ".join([s for s in OPEN_WHITELIST if isinstance(s, str) and s.strip()])
            text = text.replace("{{OPEN_WHITELIST}}", whitelist or "ï¼ˆç©ºï¼‰")
            text = text.replace("{{MIN_QUOTE_VOLUME_USDT}}", str(MIN_QUOTE_VOLUME_USDT))
            return text
    except Exception:
        return "ä½ æ˜¯ä¸€åä¸“ä¸šé‡åŒ–ç­–ç•¥åˆ†æå¼•æ“ï¼Œè¯·ä¸¥æ ¼è¾“å‡º JSON æ•°ç»„æˆ– JSON å¯¹è±¡å½¢å¼çš„äº¤æ˜“ä¿¡å·ã€‚"

###############################################
# ğŸ”¥ é›†ä¸­é¢„æ‹‰å–æ‰€æœ‰ APIï¼ˆçº¿ç¨‹æ±  + å¼‚å¸¸å®‰å…¨ï¼‰
###############################################
async def preload_all_api(dataset):
    results = {
        "funding": {},
        "p24": {},
        "oi": {},
        "sentiment": {},
        "oi_hist": {},
        "big_pos": {},
        "big_acc": {},
        "global_acc": {},
    }

    def safe_call(func, *args, **kwargs):
        try:
            return func(*args, **kwargs)
        except:
            return None

    loop = asyncio.get_running_loop()
    executor = ThreadPoolExecutor(max_workers=20)

    tasks = []
    for symbol, cycles in dataset.items():
        # å• symbol
        tasks.append(loop.run_in_executor(executor, safe_call, get_funding_rate, symbol))
        tasks.append(loop.run_in_executor(executor, safe_call, get_24hr_change, symbol))
        tasks.append(loop.run_in_executor(executor, safe_call, get_open_interest, symbol))

        for interval in cycles.keys():
            key = f"{symbol}:{interval}"
            tasks.append(loop.run_in_executor(executor, safe_call, get_oi_history, symbol, interval, 10))
            tasks.append(loop.run_in_executor(executor, safe_call, get_top_position_ratio, symbol, interval, 1))
            tasks.append(loop.run_in_executor(executor, safe_call, get_top_account_ratio, symbol, interval, 1))
            tasks.append(loop.run_in_executor(executor, safe_call, get_global_account_ratio, symbol, interval, 1))
            tasks.append(loop.run_in_executor(executor, safe_call, calc_smart_sentiment, symbol, interval))

    # æ‰§è¡Œä»»åŠ¡
    completed = await asyncio.gather(*tasks)

    # æŒ‰é¡ºåºå¡«å……ç»“æœ
    idx = 0
    for symbol, cycles in dataset.items():
        results["funding"][symbol] = completed[idx]; idx += 1
        results["p24"][symbol] = completed[idx]; idx += 1
        results["oi"][symbol] = completed[idx]; idx += 1
        for interval in cycles.keys():
            key = f"{symbol}:{interval}"
            results["oi_hist"][key] = completed[idx]; idx += 1
            results["big_pos"][key] = completed[idx]; idx += 1
            results["big_acc"][key] = completed[idx]; idx += 1
            results["global_acc"][key] = completed[idx]; idx += 1
            results["sentiment"][key] = completed[idx]; idx += 1

    return results

def _extract_decision_block(content: str):
    match = re.search(r"<decision>([\s\S]*?)</decision>", content, flags=re.I)
    if not match:
        return None
    block = match.group(1).strip()
    try:
        parsed = json.loads(block)
        if isinstance(parsed, list):
            return parsed
    except:
        pass
    return None

def _extract_all_json(content: str):
    results = []
    try:
        parsed = json.loads(content)
        if isinstance(parsed, list):
            return [x for x in parsed if isinstance(x, dict) and "action" in x]
    except:
        pass

    matches = re.findall(r'\{[^{}]*\}', content, flags=re.S)
    for m in matches:
        try:
            obj = json.loads(m)
            if isinstance(obj, dict) and "action" in obj:
                results.append(obj)
        except:
            pass
    return results if results else None
    
###############################################
# ğŸ”¥ æ–°ç‰ˆ _format_datasetï¼ˆä¸æ”¹å˜ä¸šåŠ¡é€»è¾‘ï¼‰
###############################################
def _format_dataset(dataset, preloaded):
    start_time = time.time()
    text = []
    append = text.append

    # ===== è´¦æˆ·èµ„é‡‘ & æŒä»“ =====
    account = account_snapshot
    append("========= ğŸ“Œ å½“å‰è´¦æˆ·èµ„é‡‘çŠ¶æ€ =========")
    append(f"ğŸ’° æ€»æƒç›Š Balance: {round(account['balance'], 4)}")
    append(f"ğŸ”“ å¯ç”¨ä½™é¢ Available: {round(account['available'], 4)}")
    append(f"ğŸ“‰ æ€»æœªå®ç°ç›ˆäº PnL: {round(account['total_unrealized'], 4)}")

    if account["positions"]:
        append("\nğŸ“Œ å½“å‰æŒä»“:")
        for p in account["positions"]:
            amt = float(p["size"])
            entry = float(p["entry"])
            mark = float(p["mark_price"])
            pnl = float(p["pnl"])
            lev = int(p["leverage"])
            side_icon = "ğŸŸ¢ å¤š" if amt > 0 else "ğŸ”´ ç©º"
            pnl_pct = round((mark - entry) / entry * 100, 2) if entry > 0 and amt > 0 else round((entry - mark) / entry * 100, 2) if entry > 0 else 0

            line = f"{p['symbol']} | {side_icon} | æ•°é‡ {abs(amt)} | å…¥åœº {entry} â†’ å½“å‰ä»·æ ¼ {mark} | ğŸ’µ ç›ˆäº {pnl} ({pnl_pct}%)"
            pos_side = "LONG" if amt > 0 else "SHORT"
            tp_sl_orders = tp_sl_cache.get(p['symbol'], {}).get(pos_side, [])
            if tp_sl_orders:
                tp_sl_lines = [f"{o['type']}={o['stopPrice']}" for o in tp_sl_orders]
                line += " | TP/SL: " + ", ".join(tp_sl_lines)
            else:
                line += " | TP/SL: æ— "
            append(line)
    else:
        append("\nğŸ“Œ å½“å‰æ— æŒä»“")

    # ===== å¤šå‘¨æœŸå¾ªç¯ =====
    for symbol, cycles in dataset.items():
        append(f"\n============ {symbol} å¤šå‘¨æœŸè¡Œæƒ…å¿«ç…§ ============")
        fr     = preloaded["funding"].get(symbol)
        p24    = preloaded["p24"].get(symbol)
        oi_now = preloaded["oi"].get(symbol)

        if p24:
            append(f"â€¢ 24h æ¶¨è·Œå¹…: {p24['priceChangePercent']}% â†’ æœ€æ–° {p24['lastPrice']} (é«˜ {p24['highPrice']} / ä½ {p24['lowPrice']})")
            append(f"â€¢ 24h æˆäº¤é¢: {round(p24['quoteVolume']/1e6, 2)}M USD")

        append(f"ğŸ’° å½“å‰èµ„é‡‘è´¹ç‡ Funding Rate: {fr if fr is not None else 'æœªçŸ¥'}")

        for interval, data in cycles.items():
            kl = data["klines"]
            ind = data["indicators"]
            last = kl[-1]
            append(f"\n--- {interval} ---")
            append(f"ğŸ“Œ å½“å‰å‘¨æœŸæ”¶ç›˜ä»·æ ¼: {last['Close']}")
            key = f"{symbol}:{interval}"

            oi_hist    = preloaded["oi_hist"].get(key)
            big_pos    = preloaded["big_pos"].get(key)
            big_acc    = preloaded["big_acc"].get(key)
            global_acc = preloaded["global_acc"].get(key)
            sentiment  = preloaded["sentiment"].get(key)

            append(f"ğŸ§± å½“å‰æ°¸ç»­æœªå¹³ä»“é‡ OI: {oi_now if oi_now is not None else 'æœªçŸ¥'}")

            if oi_hist:
                arr = [round(i["openInterest"], 2) for i in oi_hist][-10:]
                append(f"â€¢æœ€æ–°10æ¡å†å² OI æ•°æ®è¶‹åŠ¿: {arr}")

            if big_pos:
                b = big_pos[-1]
                append(f"â€¢ å¤§æˆ·æŒä»“é‡å¤šç©ºæ¯”: {b['ratio']} (å¤š {b['long']}, ç©º {b['short']})")
            if big_acc:
                b = big_acc[-1]
                append(f"â€¢ å¤§æˆ·è´¦æˆ·æ•°å¤šç©ºæ¯”: {b['ratio']} (å¤š {b['long']}, ç©º {b['short']})")
            if global_acc:
                g = global_acc[-1]
                append(f"â€¢ å…¨ç½‘å¤šç©ºäººæ•°æ¯”: {g['ratio']} (å¤š {g['long']}, ç©º {g['short']})")

            append("\nğŸ“Œ CVD æŒ‡æ ‡:")
            for keycv in ["CVD", "CVD_MOM", "CVD_DIVERGENCE", "CVD_PEAKFLIP", "CVD_NORM"]:
                if keycv in ind:
                    append(f"{keycv}: {ind[keycv]}")

            if sentiment:
                try:
                    score = sentiment["sentiment_score"]
                    fac = sentiment["factors"]
                    append("\nğŸ“Œ Smart Sentiment Score:")
                    append(f"ğŸ¯ æƒ…ç»ªè¯„åˆ†: {score}/100")
                    append("ğŸ“Š åˆ†é¡¹å› å­(å½’ä¸€åŒ–):")
                    append(f"Â· OIæƒ…ç»ª: {fac['open_interest']}")
                    append(f"Â· Fundingæƒ…ç»ª: {fac['funding_rate']}")
                    append(f"Â· å¤§æˆ·æƒ…ç»ª: {fac['big_whales']}")
                    append(f"Â· æ•£æˆ·åå‘æƒ…ç»ª: {fac['retail_inverse']}")
                    append(f"Â· æˆäº¤é‡æƒ…ç»ª: {fac['volume_emotion']}")
                except Exception:
                    append("\nğŸ“Œ Smart Sentiment Score: è®¡ç®—å¤±è´¥")
            else:
                append("\nğŸ“Œ Smart Sentiment Score: è®¡ç®—å¤±è´¥")

            append("\nğŸ“Œ æ³¢åŠ¨ç‡æŒ‡æ ‡:")
            if "ATR" in ind:
                append(f"ATR: {ind['ATR']:.6f}")
            if "ATR_MA20" in ind:
                append(f"ATR 20å‘¨æœŸå‡å€¼: {ind['ATR_MA20']:.6f}")

            last_buy  = float(last["TakerBuyVolume"])
            last_sell = float(last["TakerSellVolume"])
            last_vol  = float(last["Volume"])
            ratio     = round(last_buy / last_vol * 100, 2) if last_vol > 0 else 0

            append("\nğŸ“Œ ä¸»åŠ¨äº¤æ˜“é‡:")
            append(f"ä¸»åŠ¨ä¹°å…¥é‡(Taker Buy): {last_buy}")
            append(f"ä¸»åŠ¨å–å‡ºé‡(Taker Sell): {last_sell}")
            append(f"ä¸»åŠ¨ä¹°å…¥å æ¯”: {ratio}%")

            vol_info = calc_volume_compare(kl)
            if vol_info:
                append("\nğŸ“Œ æˆäº¤é‡å¯¹æ¯”:")
                append(f"å½“å‰æˆäº¤é‡: {vol_info['current_volume']}")
                append(f"100æ ¹å‡é‡: {vol_info['average_volume_100']}")
                append(f"å½“å‰/å‡é‡æ¯”å€¼: {vol_info['ratio']}")

            opens   = [k["Open"] for k in kl]
            highs   = [k["High"] for k in kl]
            lows    = [k["Low"] for k in kl]
            closes  = [k["Close"] for k in kl]
            volumes = [k["Volume"] for k in kl]
            append("\nğŸ“Œ Kçº¿æ•°ç»„æ ¼å¼ä»æ—§ â†’ æ–°:")
            append(f"open: {opens}")
            append(f"high: {highs}")
            append(f"low: {lows}")
            append(f"close: {closes}")
            append(f"volume: {volumes}")

    # append("\nğŸ§  ç°åœ¨è¯·åˆ†æå¹¶è¾“å‡ºå†³ç­–ï¼ˆç®€æ´æ€ç»´é“¾ < 150 å­— + JSONï¼‰")
    #è°ƒè¯•å®Œæ¯•åå¯ä»¥ä¸è¾“å‡ºæ€ç»´é“¾,èŠ‚çº¦token
    append("\nğŸ§  è¯·ç›´æ¥è¾“å‡ºäº¤æ˜“å†³ç­–ï¼Œä¸éœ€è¦æ¨ç†è¿‡ç¨‹ï¼Œåªéœ€JSONæ ¼å¼ï¼š")
    append("æŒ‡ä»¤ï¼šåªè¾“å‡º<decision>æ ‡ç­¾å†…çš„JSONæ•°ç»„ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—ã€‚")
    end_time = time.time()
    print(f"[_format_dataset] å‡½æ•°æ‰§è¡Œè€—æ—¶: {end_time - start_time:.3f} ç§’")
    return "\n".join(text)

###############################################
# ğŸ”¥ DeepSeek æŠ•å–‚
###############################################
async def push_batch_to_deepseek():
    if not _is_ready_for_push():
        return None

    dataset = batch_cache.copy()
    batch_cache.clear()
    timestamp = int(time.time() * 1000)
    loop = asyncio.get_running_loop()

    print("â³ é¢„åŠ è½½å¤šå‘¨æœŸæ•°æ®â€¦â€¦")
    preloaded = await preload_all_api(dataset)
    print("ğŸ“Œ é¢„åŠ è½½å®Œæˆ âœ“")

    formatted_dataset = await loop.run_in_executor(None, _format_dataset, dataset, preloaded)
    system_prompt = await loop.run_in_executor(None, _read_prompt)

    # å…¼å®¹é˜¿é‡Œåƒé—® DashScope çš„å…¼å®¹æ¨¡å¼ï¼ˆOpenAI æ¥å£è·¯å¾„ /chat/completionsï¼‰
    endpoint = DEEPSEEK_URL.rstrip("/")
    if endpoint.endswith("/v1"):
        endpoint = f"{endpoint}/chat/completions"

    payload = {
        "model": DEEPSEEK_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": formatted_dataset}
        ],
        "temperature": 0.1,
        "max_tokens": 8000,
        "stream": False
    }

    redis_client.lpush(KEY_REQ, json.dumps({
        "timestamp": timestamp,
        "request": formatted_dataset
    }, ensure_ascii=False))

    start = time.perf_counter()
    print("â³ æ­£åœ¨è¯·æ±‚ DeepSeekâ€¦")

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(endpoint, json=payload,
                                    headers={"Authorization": f"Bearer {DEEPSEEK_API_KEY}"}) as resp:
                raw = await resp.text()
                cost = round((time.perf_counter() - start) * 1000, 2)
                print(f"DeepSeek å·²è¿”å› | è€—æ—¶ {cost} ms")

                def parse_ai_response(raw):
                    try:
                        root = json.loads(raw)
                        content = root["choices"][0]["message"]["content"]
                    except:
                        return None
                    d = _extract_decision_block(content)
                    if d: return d
                    return _extract_all_json(content)

                signals = await loop.run_in_executor(None, parse_ai_response, raw)

                redis_client.lpush(KEY_RES, json.dumps({
                    "timestamp": timestamp,
                    "response_raw": raw,
                    "response_json": signals,
                    "status_code": resp.status,
                    "cost_ms": cost
                }, ensure_ascii=False))

                print(f"â± DeepSeek å“åº”è€—æ—¶: {cost} ms   HTTP: {resp.status}")
                return signals

    except Exception as e:
        logging.error(f"âŒ DeepSeek è°ƒç”¨å¤±è´¥ï¼š{e}")
        return None
